)
ifelse(alunos.df$years >= 18, alunos$teen'Maior', alunos$teen'Menor')
alunos['teen'] <- ifelse(alunos.df$years >= 18, 'Maior', 'Menor')
alunos.df <- data.frame(
name = c('Maria', "Mário", 'Joana', 'João'),
state = c('PR', 'PR', 'SC', 'RS'),
years = c(21,16,29,14)
)
alunos['teen'] <- ifelse(alunos.df$years >= 18, 'Maior', 'Menor')
alunos.df <- data.frame(
name = c('Maria', "Mário", 'Joana', 'João'),
state = c('PR', 'PR', 'SC', 'RS'),
years = c(21,16,29,14)
)
alunos.df['teen'] <- ifelse(alunos.df$years >= 18, 'Maior', 'Menor')
alunos
alunos.df
alunos.df <- data.frame(
name = c('Maria', "Mário", 'Joana', 'João'),
state = c('PR', 'PR', 'SC', 'RS'),
years = c(21,16,29,14)
)
alunos.$teen <- ifelse(alunos.df$years >= 18, 'Maior', 'Menor')
alunos.df <- data.frame(
name = c('Maria', "Mário", 'Joana', 'João'),
state = c('PR', 'PR', 'SC', 'RS'),
years = c(21,16,29,14)
)
alunos.df$teen <- ifelse(alunos.df$years >= 18, 'Maior', 'Menor')
vector1 <- 1:10
vector2 <- c("Odd", "Loop", letters[1:8])
vector3 <- rnorm(10, sd = 10)
df1 <- data.frame(vector1, vector2, vector3, stringsAsFactors = FALSE)
df1
for (i in df1) {
print(i)
}
potencia <- function(x,n) {return (x^n)}
potencia(2,3)
potencia(2,15)
potencia(2,150)
potencia(2)
potencia <- function(x,n=2) {return (x^n)}
potencia(2)
potencia(2, 3)
source("~/r_ufpr/teste.r")
source("~/r_ufpr/teste.r")
potencia(2, 3)
potencia(2, 3)
x <- 1
if (x < 0) {
sinal <- "negativo"
} else if (x == 0) {
sinal <- "neutro"
} else if (x > 0) {
sinal <- "positivo"
}
print(sinal)
source("~/r_ufpr/teste.r")
source("~/r_ufpr/teste.r")
potencia <- function(x, expoente) {
return (x^expoente)
}
dados <- 10:20
dados
sapply(dados, potencia)
sapply(dados, potencia, 2)
sapply(dados, potencia, 3)
potencia(dados, 2)
potencia(dados, 3)
lapply(dados, potencia, 3)
apply(dados, potencia, 3)
matriz <- matrix(1:12, nrow=3, ncol=4)
matriz
apply(matriz, 1, sum)
apply(matriz, 2, sum)
apply(matriz, 3, sum)
iris
head(iris)
tapply(iris$Spepal.width, iris$species, mean)
tapply(iris$Spepal.Width, iris$Species, mean)
tapply(iris$Sepal.Width, iris$Species, mean)
summary(iris)
rnorm(10)
mean(rnorm(10))
x <- c(22,7,19,8,9,19,10)
range(x)
diff(range(x))
sd(x)
mean(x)
var(x)
x <- c(543, 1078, 930, 3529, 322)
prop.table(x)
prop.table(x)*100
sum(prop.table(x)*100)
rep("Grupo A", sample(1:100, 1))
grupoA <- rep("Grupo A", sample(1:100, 1))
grupoB <- rep("Grupo B", sample(1:100, 1))
grupoC <- rep("Grupo C", sample(1:100, 1))
grupos <- sample(c(grupoA, grupoB, grupoC))
grupos
table(grupos)
prop.table(grupos)
prop.table(table(grupos))
prop.table(table(grupos))*100
install.packages('ggplot')
install.packages('ggplot2')
library("MASS")
str(Cars93)
Cars93
head(Cars93)
plot(Cars93$Price, Cars93$MPG.city)
plot(Cars93$Price, Cars93$MPG.city, main="Consumo x Preço", xlab="Preço (Mil USD)", ylab="Consumo (MPG)")
max(Cars93$Price)
barplot(sort(Cars93$RPM))
barplot(Table(Cars93$Type))
barplot(table(Cars93$Type))
help(barplot)
barplot(table(Cars93$Type), legend.text=T)
hist(Cars93$Price)
pie(table(Cars93$Passengers))
pie(table(Cars93$Passengers), legend.text=T)
t <- table(Cars$Type)
t <- table(Cars93$Type)
porcentagens <- round(100*t/sum(t), 1)
porcentagens
pie(table(Cars93$Type), labels=porcentagens, main='Quantidade por tipo', col=c('blue', 'red', 'green', 'purple', 'yellow', 'cyan'))
legend('topright', legend=names(t), cex=0.7)
boxplot(Cars93$Horsepower ~ Cars93$Cylinders, xlab="Cilindros", ylab="Potência")
library(ggplot2)
ggplot(data=Cars93, aes(x=Type)) + geom_bar()
install.packages("ggthemes")
library('ggthemes')
ggplot(data=Cars93, aes(x=Type)) + geom_bar() +
labs (title= "Gráfico do tipo do automível", x="Tipo", y="Quantidade") +
theme_economist()
ggplot(Cars93, aes(x=Horsepower, y=MPG.city)) + geom_point(shape=21, color='red', size=2) +
labs(x="Potência", y="Consumo", title="Diagrama de dispersão", subtitle='Consumo x potência')
ggplot(Cars93, aes(x=Horsepower, y=Price)) + geom_line()
ggplot(Cars93, aes(x=Horsepower, y=Price)) + geom_bloxplot()
ggplot(Cars93, aes(x=Horsepower, y=Price)) + geom_boxplot()
ggplot(Cars93, aes(x=Cylinders, y=Horsepower)) + geom_boxplot()
help("read.table")
help(read.xlsx)
help('read.xlsx')
help('read.xlxs')
help('read.excel')
help("read.excel")
help("read.xlsx")
help("read.table")
matriz <- matrix(5:16, nrow=3, ncol=4)
apply(matriz, 1, mean)
matriz
apply(matriz, 1, mean)
Cars93
iris
head(iris)
head(iris$Species)
table(iris$Species)
head(iris[iris$Species, iris$Sepal.Length])
summary(iris)
head(iris['iris$Species', 'iris$Sepal.Length'])
head(iris[1])
head(iris[1, 2])
install.packages('e1071')
install.packages("randomFores")
install.packages("randomForest")
install.packages("kernlab")
install.packages("caret")
library('caret')
str(iris)
set.seed(7)
indices <- createDataPartition(iris$Species, p=0.80, list=FALSE)
treino <- iris[indices, ]
iris[indices, ]
teste <- iris[-indices, ]
indices
rf <- train(Species~., data=treino, method='rf')
rf
help("train")
predicoes.rf <- predict(rf, teste)
predicoes.rf
plot(preticoes.rf)
plot(predicoes.rf)
help('predict')
confusionMatrix(predicoes.rf, teste$Species)
svm <- train(Species~., data=treino, method='svmRadial')
svm
treino$Species
predicoes.svm <- predict(svm, teste)
confusionMatrix(predicoes.svm, teste$Species)
novos_dados <- data.frame(Sepal.Lenth=4.2, Sepal.Width=3.2, Petal.Length=1.1, Petal.Width=0.3)
predict(rf, novos_dados)
novos_dados <- data.frame(Sepal.Length=4.2, Sepal.Width=3.2, Petal.Length=1.1, Petal.Width=0.3)
predict(rf, novos_dados)
View(rf)
install.packages("mlbench")
install.packages("mice")
library(mlbench)
library(micr)
library(mice)
data("BreastCancer")
summary(BreastCancer)
BreastCancer
head(BreastCancer)
head(BreastCancer[,-Id])
head(BreastCancer[,-BreastCancer$Id])
head(BreastCancer[,BreastCancer$Id])
head(BreastCancer[,BreastCancer$Id,])
head(BreastCancer[ ,BreastCancer$Id])
BreastCancer[ ,BreastCancer$Id]
BreastCancer[ ,'Id']
BreastCancer[ ,-'Id']
BreastCancer[ ,-Id]
BreastCancer[ ,Id]
BreastCancer[ ,BreastCancer%Id]
BreastCancer[ ,BreastCancer$Id]
BreastCancer[ ,Id]
BreastCancer[ ,"Id"]
BreastCancer[ ,-"Id"]
temp_dados <- BreastCancer
set.seed(7)
temp_dados$Id <- NULL
imp <- mice(temp_dados)
dados <- complete(imp, 1)
indices <- createDataPartition(dados$Class, p=0.80, list=FALSE)
treino <- dados[indices, ]
teste <- dados[-indices,]
df <- train(Class~., data=treino, method='rf')
df
rf <- train(Class~., data=treino, method='rf')
svm <- train(Class~., data=treino, method='svmRadial')
rna <- train(Class~., data=treino, method='nnet')
predict.rf <- predict(rf, teste)
predict.svm <- predict(svm, teste)
predict.rna <- predict(rna, teste)
predict.rf
predict.svm
confusionMatrix(predict.rf, teste$Class)
confusionMatrix(predict.svm, teste$Class)
confusionMatrix(predict.rna, teste$Class)
x <- c(40, 30, 30, 25, 50, 60, 65, 10, 20, 55, 40, 35, 30)
y <- c(1000, 1500, 1200, 1800, 800, 1000, 500, 3000, 2500, 2000, 800, 1500, 2000, 2000)
modelo <- lm(y ~ x)
x <- c(40, 30, 30, 25, 50, 60, 65, 10, 15, 20, 55, 40, 35, 30)
modelo <- lm(y ~ x)
modelo
plot(modelo)
help('lm')
summary(modelo)
str(modelo)
modelo$coefficients
coef(modelo)
help('predict')
base_de_teste = c(1500)
predict(modelo, data=base_de_teste)
resid(modelo)
base_de_teste = c(1500, 1200)
predict(modelo, data=base_de_teste)
install.packages('RSNNS')
library(RSNNS)
df <- read.csv('http://www.razer.net.br/datasets/real-state.csv', sep=';', dec=',')
df
head(df)
summary(df)
df$No <- NULL
df[, df$X1.transaction.date]
set.seed(7)
indices <- createDataPartition(df$Y.house.price.of.unit.area, p=0.80, list=FALSE)
treino <- df[indices,]
teste <- df[-indices,]
rf <- caret::train(Y.house.price.of.unit.area~., data=treino, method='rf')
predicoes.rf <- predict(rf, teste)
svm <- caret::train(Y.house.price.of.unit.area~., data=treino, method='svmRadial')
predicoes.svm <- predict(svm, teste)
predicoes.rf
confusionMatrix(predict.rf, teste$Y.house.price.of.unit.area)
predicoes.svm
help('confusionMatrix')
rna <- caret::train(Y.house.price.of.unit.area~., data=treino, method='nnet')
predicoes.rna <- predict(rna, teste)
model.mlp <- mlp(treino[, 1:6], treino[,7], linOut=T)
predicoes.mlp <- predict(model.mlp, teste[,1:6])
plot(predicoes.mlp)
head(df)
install.packages('neuralnet')
install.packages('mlbench')
install.packages("mlbench")
data(Satellite)
data('Satellite')
library('mlbench')
data("Satellite")
Satellite
summary(Satellite)
source("~/r_ufpr/teste.r")
library(mlbench)
library(caret)
library(neuralnet)
library(randomForest)
library(e1071)
data(Satellite)
set.seed(7)
# Criar particao 80 treinamento e 20 testes
trainIndex <- createDataPartition(Satellite$classes, p = 0.8, list = FALSE)
trainData <- Satellite[trainIndex, ]
testData <- Satellite[-trainIndex, ]
# Treinar RandomForest e imprimir matriz confusao
rf_model <- randomForest(classes ~ ., data = trainData)
rf_pred <- predict(rf_model, testData)
cf_rf <- confusionMatrix(rf_pred, testData$classes)
print("Matriz Confusao RF")
print(cf_rf)
cf_rf$overall
cf_rf$overall$Accuracy
cf_rf$overall
help('randomForest')
help('train')
help('carret::train')
library(mlbench)
library(caret)
library(neuralnet)
library(randomForest)
library(e1071)
data(Satellite)
set.seed(7)
# Criar particao 80 treinamento e 20 testes
trainIndex <- createDataPartition(Satellite$classes, p = 0.8, list = FALSE)
trainData <- Satellite[trainIndex, ]
testData <- Satellite[-trainIndex, ]
# Treinar RandomForest e imprimir matriz confusao
rf_model <- randomForest(classes ~ ., data = trainData)
rf_pred <- predict(rf_model, testData)
cf_rf <- confusionMatrix(rf_pred, testData$classes)
print("Matriz Confusao RF")
print(cf_rf)
library(mlbench)
library(caret)
library(neuralnet)
library(randomForest)
library(e1071)
data(Satellite)
set.seed(7)
# Criar particao 80 treinamento e 20 testes
trainIndex <- createDataPartition(Satellite$classes, p = 0.8, list = FALSE)
trainData <- Satellite[trainIndex, ]
testData <- Satellite[-trainIndex, ]
# Treinar RandomForest e imprimir matriz confusao
rf_model <- randomForest(classes ~ ., data = trainData)
rf_pred <- predict(rf_model, testData)
cf_rf <- confusionMatrix(rf_pred, testData$classes)
# Treinar SVM e imprimir matriz confusao
svm_model <- svm(classes ~ ., data = trainData)
svm_pred <- predict(svm_model, testData)
svm_cm <- confusionMatrix(svm_pred, testData$classes)
# Treinar RNA e imprimir matriz confusao
rna_model <- train(classes ~ ., data=trainData, method="nnet", trace=FALSE)
rna_pred <- predict(rna_model, testData)
rna_cm <- confusionMatrix(rna_pred, testData$classes)
print("Comparação")
print("Matriz Confusao RF")
print(cf_rf$overall)
print("Matriz Confusao SVM")
print(svm_cm$overall)
print("Matriz Confusao RNA")
print(rna_cm$overall)
# Treinar RNA e imprimir matriz confusao
rna_model <- train(classes ~ ., data=trainData, method="nnet")
rna_pred <- predict(rna_model, testData)
rna_cm <- confusionMatrix(rna_pred, testData$classes)
print("Comparação")
print("Matriz Confusao RF")
print(cf_rf$overall)
print("Matriz Confusao SVM")
print(svm_cm$overall)
print("Matriz Confusao RNA")
print(rna_cm$overall)
summary(trainData)
library(mlbench)
library(caret)
library(neuralnet)
library(randomForest)
library(e1071)
data(Satellite)
set.seed(7)
# Criar particao 80 treinamento e 20 testes
trainIndex <- createDataPartition(Satellite$classes, p = 0.8, list = FALSE)
trainData <- Satellite[trainIndex, ]
testData <- Satellite[-trainIndex, ]
# Treinar RandomForest e imprimir matriz confusao
rf_model <- randomForest(classes ~ ., data = trainData)
rf_pred <- predict(rf_model, testData)
cf_rf <- confusionMatrix(rf_pred, testData$classes)
print("Matriz Confusao RF")
print(cf_rf)
# Treinar SVM e imprimir matriz confusao
svm_model <- svm(classes ~ ., data = trainData)
svm_pred <- predict(svm_model, testData)
svm_cm <- confusionMatrix(svm_pred, testData$classes)
print("Matriz Confusao SVM")
print(svm_cm)
# Treinar RNA e imprimir matriz confusao
print("Treinando RNA...")
rna_model <- train(classes ~ ., data=trainData, method="nnet", trace=FALSE)
rna_pred <- predict(rna_model, testData)
rna_cm <- confusionMatrix(rna_pred, testData$classes)
print("Matriz Confusao RNA")
print(rna_cm)
help('randomForest')
library(mlbench)
library(caret)
library(neuralnet)
library(randomForest)
library(e1071)
# Funcao para calcular R², Syx, and Syx%
calcular_metricas <- function(atual, predito) {
# Residuais
residuais <- atual - predito
# Quadrado dos residuais
ssr <- sum(residuais^2)
# Total quadrados
sst <- sum((atual - mean(atual))^2)
# R²
r_squared <- 1 - (ssr / sst)
# Syx
syx <- sqrt(ssr / (length(atual) - 2))
# Syx%
syx_percentage <- (syx / mean(atual)) * 100
return(list(R2 = r_squared, Syx = syx, Syx_percent = syx_percentage))
}
# Ler arquivo CSV
data <- read.csv2("http://www.razer.net.br/datasets/Volumes.csv")
# Remover coluna NR
data$NR <- NULL
set.seed(7)
# Criar particao 80 treinamento e 20 testes
train_indices <- createDataPartition(data$VOL, p=0.80, list=FALSE)
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
# Treinar RandomForest
rf_model <- randomForest(VOL ~ ., data = train_data)
rf_predictions <- predict(rf_model, test_data)
# Treinar SVM
svm_model <- svm(VOL ~ ., data = train_data)
svm_predictions <- predict(svm_model, test_data)
# Treinar Neural Network
print("Treinando RNA...")
nn_model <- train(VOL ~ ., data=train_data, method="nnet", trace=FALSE)
nn_predictions <- predict(nn_model, test_data)
# Treinar SPURR
spurr_model <- nls(VOL ~ b0 + b1*DAP*DAP*HT, train_data, start=list(b0=0.5, b1=0.5))
spurr_predictions <- predict(spurr_model, test_data)
# Calcular e imprimir metricas RandomForest
rf_metrics <- calcular_metricas(test_data$VOL, rf_predictions)
print("Metrics for RandomForest model:")
print(rf_metrics)
# Calcular e imprimir metricas SVM
svm_metrics <- calcular_metricas(test_data$VOL, svm_predictions)
print("Metrics for SVM model:")
print(svm_metrics)
# Calcular e imprimir metricas Neural Network
nn_metrics <- calcular_metricas(test_data$VOL, nn_predictions)
print("Metrics for Neural Network model:")
print(nn_metrics)
# Calcular e imprimir metricas SPURR
spurr_metrics <- calcular_metricas(test_data$VOL, spurr_predictions)
print("Metrics for SPURR model:")
print(spurr_metrics)
# Vamos carregar o dataset
load("imoveiscwbav.RData")
workdir
workdir()
getwd()
setwd("C:\Users\matheus.arazao\OneDrive - COMPASSO TECNOLOGIA LTDA\Área de Trabalho\git\matheusarazao\ufpr\ufpr-lpa-trabalho\Estatística II\course_content")
setwd("C:\\Users\\matheus.arazao\\OneDrive - COMPASSO TECNOLOGIA LTDA\\Área de Trabalho\\git\\matheusarazao\\ufpr\\ufpr-lpa-trabalho\\Estatística II\\course_content")
# Vamos carregar o dataset
load("bases\imoveiscwbav.RData")
# Vamos carregar o dataset
load("\\bases\\imoveiscwbav.RData")
# Vamos carregar o dataset
load("\bases\imoveiscwbav.RData")
getwd()
# Vamos carregar o dataset
load("/bases/imoveiscwbav.RData")
# Vamos carregar o dataset
load("bases/imoveiscwbav.RData")
View(imoveiscwbav)
View(imoveiscwbav)
# Vamos ver a base de dados
View(imoveiscwbav)
# Para um exemplo de correlacao entre variaveis, vamos estimar a
# matriz de correlacao das variaveis "price", "parea" e "tarea"
cor(imoveiscwbav[,c("price","parea","tarea")], use="complete")
# Vamos ver a base de dados
View(imoveiscwbav)
# Vamos guardar o dataset em um outro objeto chamado "imoveis"
imoveis <- imoveiscwbav
imoveis(1,)
imoveis([1],)
imoveis[1, ]
# Vamos evitar a notacao cientifica nos resultados
options(scipen = 999)
# Vamos agora estimar o modelo linear por MQO com o preco em
# logaritmo neperiano que no "R" eh "log"; o "." quer dizer que
# estamos regredindo o ln do preco contra todas as demais
# variaveis, ou seja, todas as demais variaveis do dataset sao
# variaveis explicativas (Xs) no nosso modelo. Estamos guardando
# os resultados da estimativa em um objeto chamado "resultados"
resultados <- lm(log(price)~., data=imoveis)
# Vamos visualizar os resultados com a funcao "summary"
summary(resultados)
qnorm(0.975)
qf(0.95, 19, 521)
