{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inteligência artificial aplicada\n",
    "## Arquitetura de dados\n",
    "### Trabalho da disciplina - Questão 2\n",
    "\n",
    "Nomes: Paulo Sergio Herval Silva Junior, Pedro de Sousa Alves Graça, Matheus Eduardo de Arazão e Anderson Felipe de Paiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando dados\n",
    "Dataset:\n",
    "https://archive.ics.uci.edu/dataset/602/dry+bean+dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_dry_bean = pd.read_excel('data/Dry_Bean_Dataset.xlsx')\n",
    "\n",
    "x_orig = df.iloc[:, :16]\n",
    "y_orig = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trata os dados removendo as colunas 'Area' e 'ConvexArea' e normalizando os dados por meio do StandardScaler.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_tratado = x_orig.drop(columns=['Area', 'ConvexArea'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_tratado = scaler.fit_transform(x_tratado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# treinamento com os dados originais\n",
    "x_orig_train, x_orig_test, y_orig_train, y_orig_test = train_test_split(x_orig,\n",
    "                      y_orig, test_size=0.25, stratify=y_orig,random_state=10)\n",
    "\n",
    "# treinamento com os dados tratados\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_tratado,\n",
    "                      y_orig, test_size=0.25, stratify=y_orig,random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão - com os dados ORIGINAIS usados no TREINAMENTO\n",
      "[[  56    0  673    0  234    0   29]\n",
      " [   0  390    2    0    0    0    0]\n",
      " [  42    0 1079    0   98    0    3]\n",
      " [   0    0    0 2249    0  319   91]\n",
      " [  38    0   72   23  847   47  419]\n",
      " [   0    0    0  523   36  426  535]\n",
      " [   0    0    0   97  188  261 1431]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.41      0.06      0.10       992\n",
      "      BOMBAY       1.00      0.99      1.00       392\n",
      "        CALI       0.59      0.88      0.71      1222\n",
      "    DERMASON       0.78      0.85      0.81      2659\n",
      "       HOROZ       0.60      0.59      0.59      1446\n",
      "       SEKER       0.40      0.28      0.33      1520\n",
      "        SIRA       0.57      0.72      0.64      1977\n",
      "\n",
      "    accuracy                           0.63     10208\n",
      "   macro avg       0.62      0.62      0.60     10208\n",
      "weighted avg       0.61      0.63      0.60     10208\n",
      "\n",
      "Matriz de confusão - com os dados ORIGINAIS usados para TESTES\n",
      "[[ 18   0 220   0  77   0  15]\n",
      " [  0 130   0   0   0   0   0]\n",
      " [  8   0 360   0  38   0   2]\n",
      " [  0   0   0 749   0 109  29]\n",
      " [ 10   0  28  10 289  11 134]\n",
      " [  0   0   0 169  10 136 192]\n",
      " [  0   0   0  39  48  89 483]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.50      0.05      0.10       330\n",
      "      BOMBAY       1.00      1.00      1.00       130\n",
      "        CALI       0.59      0.88      0.71       408\n",
      "    DERMASON       0.77      0.84      0.81       887\n",
      "       HOROZ       0.63      0.60      0.61       482\n",
      "       SEKER       0.39      0.27      0.32       507\n",
      "        SIRA       0.56      0.73      0.64       659\n",
      "\n",
      "    accuracy                           0.64      3403\n",
      "   macro avg       0.64      0.63      0.60      3403\n",
      "weighted avg       0.62      0.64      0.60      3403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "treinador = svm.SVC()  #algoritmo escolhido\n",
    "\n",
    "modelo_orig = treinador.fit(x_orig_train, y_orig_train)\n",
    "\n",
    "# predição com os mesmos dados usados para treinar\n",
    "y_orig_pred = modelo_orig.predict(x_orig_train)\n",
    "cm_orig_train = confusion_matrix(y_orig_train, y_orig_pred)\n",
    "print('Matriz de confusão - com os dados ORIGINAIS usados no TREINAMENTO')\n",
    "print(cm_orig_train)\n",
    "print(classification_report(y_orig_train, y_orig_pred))\n",
    "\n",
    "# predição com os mesmos dados usados para testar\n",
    "print('Matriz de confusão - com os dados ORIGINAIS usados para TESTES')\n",
    "y2_orig_pred = modelo_orig.predict(x_orig_test)\n",
    "cm_orig_test = confusion_matrix(y_orig_test, y2_orig_pred)\n",
    "print(cm_orig_test)\n",
    "print(classification_report(y_orig_test, y2_orig_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão - com os dados TRATADOS usados no TREINAMENTO\n",
      "[[ 912    0   54    0    3    5   18]\n",
      " [   0  392    0    0    0    0    0]\n",
      " [  26    0 1171    0   16    3    6]\n",
      " [   0    0    0 2477    3   36  143]\n",
      " [   2    0   16   11 1391    0   26]\n",
      " [   5    0    0   18    0 1460   37]\n",
      " [   4    0    3  170   25   21 1754]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.96      0.92      0.94       992\n",
      "      BOMBAY       1.00      1.00      1.00       392\n",
      "        CALI       0.94      0.96      0.95      1222\n",
      "    DERMASON       0.93      0.93      0.93      2659\n",
      "       HOROZ       0.97      0.96      0.96      1446\n",
      "       SEKER       0.96      0.96      0.96      1520\n",
      "        SIRA       0.88      0.89      0.89      1977\n",
      "\n",
      "    accuracy                           0.94     10208\n",
      "   macro avg       0.95      0.95      0.95     10208\n",
      "weighted avg       0.94      0.94      0.94     10208\n",
      "\n",
      "Matriz de confusão - com os dados TRATADOS usados para TESTES\n",
      "[[297   0  17   0   2   4  10]\n",
      " [  0 130   0   0   0   0   0]\n",
      " [  9   0 385   0   6   0   8]\n",
      " [  0   0   0 821   1  15  50]\n",
      " [  1   0  11   5 457   0   8]\n",
      " [  3   0   0  19   0 468  17]\n",
      " [  2   0   0  68  10   5 574]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.95      0.90      0.93       330\n",
      "      BOMBAY       1.00      1.00      1.00       130\n",
      "        CALI       0.93      0.94      0.94       408\n",
      "    DERMASON       0.90      0.93      0.91       887\n",
      "       HOROZ       0.96      0.95      0.95       482\n",
      "       SEKER       0.95      0.92      0.94       507\n",
      "        SIRA       0.86      0.87      0.87       659\n",
      "\n",
      "    accuracy                           0.92      3403\n",
      "   macro avg       0.94      0.93      0.93      3403\n",
      "weighted avg       0.92      0.92      0.92      3403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "treinador = svm.SVC()  #algoritmo escolhido\n",
    "\n",
    "modelo = treinador.fit(x_train, y_train)\n",
    "\n",
    "# predição com os mesmos dados usados para treinar\n",
    "y_pred = modelo.predict(x_train)\n",
    "cm_train = confusion_matrix(y_train, y_pred)\n",
    "print('Matriz de confusão - com os dados TRATADOS usados no TREINAMENTO')\n",
    "print(cm_train)\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "# predição com os mesmos dados usados para testar\n",
    "print('Matriz de confusão - com os dados TRATADOS usados para TESTES')\n",
    "y2_pred = modelo.predict(x_test)\n",
    "cm_test = confusion_matrix(y_test, y2_pred)\n",
    "print(cm_test)\n",
    "print(classification_report(y_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
